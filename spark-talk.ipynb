{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:42:40) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f39542bf950>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Subset Data\n",
    "\n",
    "We will first subset down the dataset of Amazon Book reviews located at [this link](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz).  This dataset contains 8,898,041 book reviews.\n",
    "\n",
    "This dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), and links (also viewed/also bought graphs).  For more information please refer to [this page](http://jmcauley.ucsd.edu/data/amazon/).\n",
    "\n",
    "The data located at `s3n://spark-talk/reviews_Books_subset5.json` contains a 5% subset of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"s3n://spark-talk/reviews_Books_subset5.json\"\n",
    "\n",
    "review_subset = spark.read.json(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews_Books_subset5.json contains 445266 elements\n"
     ]
    }
   ],
   "source": [
    "count = review_subset.count()\n",
    "print(\"reviews_Books_subset5.json contains {} elements\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of review_subset DataFrame...\n",
      "+-------+--------------------+\n",
      "|overall|          reviewText|\n",
      "+-------+--------------------+\n",
      "|    5.0|As you read, Gibr...|\n",
      "|    5.0|_The Prophet_ is ...|\n",
      "|    5.0|The Prophet is ab...|\n",
      "|    5.0|Reading a classic...|\n",
      "|    3.0|Maybe I just wasn...|\n",
      "|    5.0|Gibran gets right...|\n",
      "|    4.0|This book was the...|\n",
      "|    5.0|One of the classi...|\n",
      "|    4.0|I have no memory ...|\n",
      "|    4.0|At first, I was g...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"First 10 rows of review_subset DataFrame...\")\n",
    "review_subset.show(10, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark as ps    # for the pyspark suite\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import string\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "def extract_bow_from_raw_text(text_as_string):\n",
    "    \"\"\"Extracts bag-of-words from a raw text string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text (str): a text document given as a string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list : the list of the tokens extracted and filtered from the text\n",
    "    \"\"\"\n",
    "    if (text_as_string == None):\n",
    "        return []\n",
    "\n",
    "    if (len(text_as_string) < 1):\n",
    "        return []\n",
    "\n",
    "    import nltk\n",
    "    if '/home/hadoop/nltk_data' not in nltk.data.path:\n",
    "        nltk.data.path.append('/home/hadoop/nltk_data')\n",
    "\n",
    "    nfkd_form = unicodedata.normalize('NFKD', unicode(text_as_string))\n",
    "    text_input = nfkd_form.encode('ASCII', 'ignore')\n",
    "\n",
    "    sent_tokens = sent_tokenize(text_input)\n",
    "\n",
    "    tokens = map(word_tokenize, sent_tokens)\n",
    "\n",
    "    sent_tags = map(pos_tag, tokens)\n",
    "\n",
    "    grammar = r\"\"\"\n",
    "        SENT: {<(J|N).*>}                # chunk sequences of proper nouns\n",
    "    \"\"\"\n",
    "\n",
    "    cp = RegexpParser(grammar)\n",
    "    ret_tokens = list()\n",
    "    stemmer_snowball = SnowballStemmer('english')\n",
    "\n",
    "    for sent in sent_tags:\n",
    "        tree = cp.parse(sent)\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'SENT':\n",
    "                t_tokenlist = [tpos[0].lower() for tpos in subtree.leaves()]\n",
    "                t_tokens_stemsnowball = map(stemmer_snowball.stem, t_tokenlist)\n",
    "                #t_token = \"-\".join(t_tokens_stemsnowball)\n",
    "                #ret_tokens.append(t_token)\n",
    "                ret_tokens.extend(t_tokens_stemsnowball)\n",
    "            #if subtree.label() == 'V2V': print(subtree)\n",
    "    #tokens_lower = [map(string.lower, sent) for sent in tokens]\n",
    "\n",
    "    stop_words = {'book', 'author', 'read', \"'\", 'character', ''}.union(ENGLISH_STOP_WORDS)\n",
    "\n",
    "    tokens = [token for token in ret_tokens if token not in stop_words]\n",
    "\n",
    "    return(tokens)\n",
    "\n",
    "\n",
    "def indexing_pipeline(input_df, **kwargs):\n",
    "    \"\"\" Runs a full text indexing pipeline on a collection of texts contained\n",
    "    in a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_df (DataFrame): a DataFrame that contains a field called 'text'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : the same DataFrame with a column called 'features' for each document\n",
    "    wordlist : the list of words in the vocabulary with their corresponding IDF\n",
    "    \"\"\"\n",
    "    inputCol_ = kwargs.get(\"inputCol\", \"text\")\n",
    "    vocabSize_ = kwargs.get(\"vocabSize\", 5000)\n",
    "    minDF_ = kwargs.get(\"minDF\", 2.0)\n",
    "\n",
    "    tokenizer_udf = udf(extract_bow_from_raw_text, ArrayType(StringType()))\n",
    "    df_tokens = input_df.withColumn(\"bow\", tokenizer_udf(col(inputCol_)))\n",
    "\n",
    "    cv = CountVectorizer(inputCol=\"bow\", outputCol=\"vector_tf\", vocabSize=vocabSize_, minDF=minDF_)\n",
    "    cv_model = cv.fit(df_tokens)\n",
    "    df_features_tf = cv_model.transform(df_tokens)\n",
    "\n",
    "    idf = IDF(inputCol=\"vector_tf\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(df_features_tf)\n",
    "    df_features = idfModel.transform(df_features_tf)\n",
    "\n",
    "    return(df_features, cv_model.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(overall=5.0, reviewText=u\"As you read, Gibran's poetry brings spiritual and visual beauty to life within you. Gibran is justly famous for rich metaphors that brilliantly highlight the pursuit of Truth and Goodness amidst all the darkness and light of human nature.\", bow=[u'gibran', u'poetri', u'spiritu', u'visual', u'beauti', u'life', u'gibran', u'famous', u'rich', u'metaphor', u'pursuit', u'truth', u'good', u'dark', u'light', u'human', u'natur'], vector_tf=SparseVector(5000, {3: 1.0, 5: 1.0, 60: 1.0, 90: 1.0, 137: 1.0, 178: 1.0, 179: 1.0, 184: 1.0, 342: 1.0, 442: 1.0, 628: 1.0, 1350: 1.0, 1481: 1.0, 1806: 1.0, 2008: 1.0}), features=SparseVector(5000, {3: 1.3775, 5: 1.8214, 60: 3.0803, 90: 3.1305, 137: 3.518, 178: 3.5413, 179: 3.6397, 184: 3.6669, 342: 4.0506, 442: 4.5143, 628: 4.5919, 1350: 5.6132, 1481: 5.5098, 1806: 5.7744, 2008: 5.8573})), Row(overall=5.0, reviewText=u'_The Prophet_ is a short read (my copy checks in at just under 100 pages), but its berevity belies both the power and beauty of Gibran\\'s words.  At its simplest, it is a discourse on the human condition: love, work, joy and sorrow, crime and punishment, reason and passion, Gibran runs the gamut of emotion and being, laying bare the paradox of who we are as human beings.  While the tone is somewhat mystical (which I didn\\'t really care for), the sheer poetic beauty of his writing moved me.For example, in the chapter \"Love\", Gibran writes, \"... When love beckons to you, follow him, / Though his ways are hard and steep, / And when his wings enfold you yield to him, / Though the sword hidden among his pinions may wound you. / And when he speaks to you believe in him, / ... For even as love crowns you so shall he crucify you.  Even as he is for you growth so is he for your pruning. ...\"  The contrast, vivid metaphor and beautiful images were stunning and left me with much to think and reflect on about my own life, and the choices I\\'ve made.  It would be going too far to say that, as a result of reading \"The Prophet\" I\\'ve had an epiphany or (to take it to a ridiculous conclusion) some sort of a conversion.  Rather it has caused me to consider on a philosophical level what it is to be human means to me, and how I have demonstrated my \"human-ness\" in my life.Part poetry, part philosophy, it is simultaneously thought-provoking and emotional.  Undeniably readers will have a visceral reaction (although, apparently given the reviews of some, not all reactions are positive.)  Highly recommended, if only to cause one to examine their own life.  After all, \"the unexamined life is not worth living.\"', bow=[u'_the', u'prophet_', u'short', u'copi', u'check', u'page', u'berev', u'beli', u'power', u'beauti', u'gibran', u'word', u'simplest', u'discours', u'human', u'condit', u'love', u'work', u'joy', u'sorrow', u'crime', u'punish', u'reason', u'passion', u'gibran', u'gamut', u'emot', u'bare', u'paradox', u'human', u'tone', u'mystic', u'sheer', u'poetic', u'beauti', u'me.for', u'exampl', u'chapter', u'love', u'gibran', u'love', u'beckon', u'way', u'hard', u'steep', u'/', u'wing', u'sword', u'hidden', u'pinion', u'/', u'love', u'crown', u'growth', u'prune', u'contrast', u'vivid', u'metaphor', u'beauti', u'imag', u'life', u'choic', u'result', u'prophet', u'epiphani', u'ridicul', u'conclus', u'sort', u'convers', u'philosoph', u'level', u'human', u'human-', u'life.part', u'poetri', u'philosophi', u'thought-provok', u'emot', u'reader', u'viscer', u'reaction', u'review', u'reaction', u'posit', u'high', u'life', u'unexamin', u'life', u'worth', u'live'], vector_tf=SparseVector(5000, {5: 3.0, 6: 1.0, 12: 4.0, 16: 1.0, 19: 1.0, 22: 1.0, 24: 1.0, 36: 1.0, 43: 1.0, 57: 1.0, 60: 3.0, 63: 1.0, 67: 1.0, 76: 1.0, 88: 1.0, 90: 3.0, 99: 2.0, 118: 1.0, 125: 1.0, 158: 1.0, 201: 1.0, 219: 1.0, 238: 1.0, 252: 1.0, 257: 1.0, 317: 1.0, 335: 1.0, 384: 1.0, 409: 1.0, 521: 1.0, 574: 1.0, 579: 1.0, 654: 1.0, 772: 1.0, 790: 1.0, 864: 1.0, 903: 2.0, 931: 1.0, 1044: 1.0, 1154: 1.0, 1184: 1.0, 1350: 1.0, 1624: 1.0, 1691: 1.0, 1751: 1.0, 1801: 2.0, 1806: 1.0, 1840: 1.0, 1876: 1.0, 2044: 1.0, 2062: 1.0, 2106: 1.0, 2123: 1.0, 2287: 1.0, 2546: 1.0, 3303: 1.0, 3438: 1.0, 4426: 1.0, 4703: 1.0}), features=SparseVector(5000, {5: 5.4641, 6: 1.6922, 12: 8.3486, 16: 2.1534, 19: 2.2901, 22: 2.379, 24: 2.465, 36: 2.8895, 43: 2.8253, 57: 2.7876, 60: 9.2408, 63: 2.8869, 67: 2.9119, 76: 3.1253, 88: 3.0649, 90: 9.3916, 99: 6.3906, 118: 3.2119, 125: 3.3649, 158: 3.3958, 201: 3.5354, 219: 3.7102, 238: 3.7647, 252: 3.8531, 257: 3.8009, 317: 3.9811, 335: 4.2053, 384: 4.1804, 409: 4.1841, 521: 4.4212, 574: 4.4926, 579: 4.629, 654: 4.6459, 772: 5.0233, 790: 4.8048, 864: 4.8205, 903: 9.8792, 931: 5.024, 1044: 5.2767, 1154: 5.1864, 1184: 5.1896, 1350: 5.6132, 1624: 5.708, 1691: 5.7956, 1751: 5.6375, 1801: 11.8816, 1806: 5.7744, 1840: 5.8763, 1876: 5.8503, 2044: 5.7905, 2062: 5.8363, 2106: 6.1659, 2123: 5.8371, 2287: 6.1007, 2546: 6.1595, 3303: 6.5832, 3438: 6.4873, 4426: 7.015, 4703: 7.0663})), Row(overall=5.0, reviewText=u\"The Prophet is about a mysterious religious thinker who is about to leave for his native land.  Before he goes, many people have just one question to ask him.  In a very few words, he tells them his accumulated wisdom primarily in a nondenominational way.  The only exceptions come in the references to rebirth.  The essence of each brief lesson is that we have to step outside of our own perspective to see things in the way that God does and wants us to.Let me give you an example.  When someone transgresses either man's laws or God's laws, we tend to condemn the person harshly and focus on punishment.  This is like treating the person as though they have fallen below some level of what it is still to be human.  Yet no one does anything worse than what some person has done wrong before and will do wrong again.Surely, our reaction should still focus, like a Mother's, on the fundamental humanness of the person and our desire to have the person be a contributing, loving, and helpful part of our community.Another way to think about the lessons of The Prophet is to notice that nature loves a balance.  If we interfere with nature, nature overreacts in some new way that counters our interference.  This happens when we put too much phosphate into lakes.  Algae blooms expand exponentially to eat the phosphate.  These lessons help us to see the balance that is missing in our initial reaction.A good parallel can be found in the study of the brain.  Our initial reactions when frightened or threatened are focused in the oldest parts of the brain.  This part of the brain triggers strong chemicals to be released that engage us in &quot;fight or flight&quot; reactions that can save our lives in the near-term.  In the &quot;civilized&quot; world, we often have these reactions just to stress.  Gibran is helping us move to our highest level of consciousness by choosing our reactions, and selecting reactions that integrate all parts of our brains plus our near- and long-term best interests as individuals and as a community.Many Eastern religions encourage one to become free of the conscious mind, and that sense of objectivity is captured nicely here.  I have a feeling much like when meditating while I read The Prophet, because of its calming influence on my overreactive senses.I also think of this perspective like being on the Moon and observing the circumstances on Earth through a telescope.  With such extreme distance should come detachment from the ego, to permit good thinking.But none of these perspectives are directly suggested or alluded to.  The moral lessons are simply there, with the briefest possible examples to make them clear.  As such, they are masterpieces of good thinking, moral ethics, and fine communication.The answers are so brief and so profound that you will want to discuss them.  I suggest you select another member of your family, or a group of people from your house of worship.  The lessons are best explored by discussing tangible situations that you face every day.  Certainly, it is desirable and appropriate to consider the direct teachings of your religious heritage and beliefs in this connection.Whenever you feel overwhelmed, turn to the page in The Prophet that addresses your issue.  Like taking a warm bath, you will be soothed by the love for humanity in the answers Gibran provides.Before you speak, ask yourself who is about to speak for you and what do they want.\", bow=[u'prophet', u'mysteri', u'religi', u'thinker', u'nativ', u'land', u'mani', u'peopl', u'question', u'word', u'accumul', u'wisdom', u'nondenomin', u'way', u'onli', u'refer', u'essenc', u'brief', u'lesson', u'perspect', u'thing', u'way', u'god', u'exampl', u'someon', u'man', u'law', u'god', u'law', u'person', u'punish', u'person', u'level', u'human', u'anyth', u'wors', u'person', u'wrong', u'wrong', u'reaction', u'mother', u'fundament', u'human', u'person', u'desir', u'person', u'contribut', u'love', u'help', u'community.anoth', u'way', u'lesson', u'prophet', u'natur', u'balanc', u'natur', u'natur', u'overreact', u'new', u'way', u'interfer', u'phosphat', u'lake', u'alga', u'bloom', u'phosphat', u'lesson', u'balanc', u'initi', u'reaction.a', u'good', u'parallel', u'studi', u'brain', u'initi', u'reaction', u'oldest', u'brain', u'brain', u'trigger', u'strong', u'chemic', u'quot', u'fight', u'flight', u'quot', u'reaction', u'live', u'near-term', u'quot', u'world', u'reaction', u'gibran', u'highest', u'level', u'conscious', u'reaction', u'reaction', u'brain', u'near-', u'long-term', u'best', u'individu', u'community.mani', u'eastern', u'religion', u'free', u'conscious', u'mind', u'sens', u'object', u'feel', u'prophet', u'influenc', u'overreact', u'senses.i', u'perspect', u'moon', u'circumst', u'earth', u'telescop', u'extrem', u'distanc', u'detach', u'ego', u'good', u'thinking.but', u'perspect', u'moral', u'lesson', u'briefest', u'possibl', u'exampl', u'clear', u'masterpiec', u'good', u'think', u'moral', u'ethic', u'fine', u'communication.th', u'answer', u'brief', u'member', u'famili', u'group', u'peopl', u'hous', u'worship', u'lesson', u'tangibl', u'situat', u'day', u'desir', u'appropri', u'direct', u'teach', u'religi', u'heritag', u'belief', u'connection.whenev', u'overwhelm', u'page', u'prophet', u'issu', u'warm', u'bath', u'love', u'human', u'answer', u'gibran'], vector_tf=SparseVector(5000, {3: 3.0, 6: 4.0, 8: 1.0, 9: 1.0, 10: 2.0, 12: 2.0, 13: 1.0, 15: 1.0, 19: 1.0, 21: 1.0, 23: 5.0, 27: 1.0, 28: 1.0, 30: 1.0, 37: 2.0, 39: 1.0, 41: 3.0, 43: 1.0, 60: 3.0, 63: 1.0, 77: 1.0, 80: 1.0, 85: 1.0, 87: 1.0, 96: 1.0, 97: 1.0, 103: 1.0, 107: 1.0, 111: 1.0, 123: 1.0, 125: 2.0, 144: 1.0, 152: 1.0, 159: 1.0, 167: 2.0, 171: 1.0, 172: 1.0, 179: 3.0, 205: 1.0, 213: 1.0, 219: 2.0, 261: 1.0, 284: 3.0, 303: 1.0, 337: 2.0, 355: 1.0, 358: 1.0, 379: 1.0, 396: 5.0, 405: 2.0, 406: 1.0, 433: 1.0, 446: 1.0, 468: 1.0, 482: 1.0, 503: 2.0, 505: 1.0, 525: 2.0, 538: 2.0, 553: 1.0, 591: 4.0, 649: 1.0, 707: 1.0, 751: 1.0, 762: 2.0, 841: 2.0, 854: 1.0, 869: 1.0, 903: 6.0, 962: 1.0, 977: 1.0, 981: 1.0, 995: 1.0, 1067: 1.0, 1125: 1.0, 1153: 2.0, 1327: 2.0, 1569: 1.0, 1618: 1.0, 1635: 1.0, 1643: 1.0, 1687: 1.0, 1744: 1.0, 1774: 1.0, 1807: 1.0, 1863: 1.0, 1899: 1.0, 1920: 1.0, 1957: 1.0, 2106: 4.0, 2287: 1.0, 2390: 1.0, 2464: 1.0, 2485: 1.0, 2673: 1.0, 2816: 1.0, 2958: 1.0, 3687: 1.0, 3784: 1.0, 3986: 1.0, 4824: 1.0}), features=SparseVector(5000, {3: 4.1324, 6: 6.7687, 8: 1.8637, 9: 1.9323, 10: 4.0555, 12: 4.1743, 13: 2.0846, 15: 2.2426, 19: 2.2901, 21: 2.5046, 23: 11.932, 27: 2.4737, 28: 2.3928, 30: 2.5953, 37: 6.524, 39: 2.8382, 41: 11.3679, 43: 2.8253, 60: 9.2408, 63: 2.8869, 77: 2.9802, 80: 2.9964, 85: 3.2618, 87: 3.0037, 96: 3.2208, 97: 3.1325, 103: 3.2567, 107: 3.0906, 111: 3.1733, 123: 3.2517, 125: 6.7298, 144: 3.3731, 152: 3.416, 159: 3.6159, 167: 6.9393, 171: 3.5041, 172: 3.6195, 179: 10.9191, 205: 3.6129, 213: 3.633, 219: 7.4204, 261: 3.8428, 284: 11.7047, 303: 4.1339, 337: 8.1347, 355: 4.0975, 358: 4.086, 379: 4.2881, 396: 21.1552, 405: 8.7817, 406: 4.125, 433: 4.222, 446: 4.2334, 468: 4.6121, 482: 4.4422, 503: 8.7515, 505: 4.5125, 525: 9.0916, 538: 9.1728, 553: 4.4767, 591: 18.9962, 649: 4.565, 707: 4.665, 751: 4.8496, 762: 9.5033, 841: 9.7113, 854: 4.966, 869: 5.0165, 903: 29.6376, 962: 5.0264, 977: 5.0805, 981: 5.0698, 995: 5.3634, 1067: 5.246, 1125: 5.1117, 1153: 10.3552, 1327: 11.1813, 1569: 5.753, 1618: 5.526, 1635: 5.6959, 1643: 5.8917, 1687: 5.6287, 1744: 5.6662, 1774: 5.7658, 1807: 5.789, 1863: 5.7012, 1899: 5.6826, 1920: 5.7375, 1957: 5.7565, 2106: 24.6635, 2287: 6.1007, 2390: 6.36, 2464: 6.1712, 2485: 6.1199, 2673: 6.2754, 2816: 6.2449, 2958: 6.556, 3687: 6.6246, 3784: 6.9039, 3986: 6.8326, 4824: 7.0849})), Row(overall=5.0, reviewText=u'Reading a classic such as &quot;The Prophet&quot; is much more fruitful when it is revisited often, the lessons are applied and the reader reads as if Gibran is writing only to him or her.Sitting with this book in your hands can be like sitting across from Gibran, listening to him speak.  The accompanying art work also by Gibran gives it yet another rich element and peek into the soul of this incredible writer.Listen, embrace and breathe in these words.Open your mind and heart to The Prophet.', bow=[u'classic', u'quot', u'prophet', u'quot', u'fruit', u'lesson', u'reader', u'gibran', u'hand', u'gibran', u'art', u'work', u'gibran', u'rich', u'element', u'peek', u'soul', u'incred', u'writer.listen', u'embrac', u'breath', u'mind', u'heart', u'prophet'], vector_tf=SparseVector(5000, {16: 1.0, 24: 1.0, 41: 2.0, 66: 1.0, 97: 1.0, 130: 1.0, 256: 1.0, 292: 1.0, 342: 1.0, 348: 1.0, 356: 1.0, 396: 1.0, 619: 1.0, 895: 1.0, 1838: 1.0, 2106: 2.0, 3892: 1.0, 4282: 1.0}), features=SparseVector(5000, {16: 2.1534, 24: 2.465, 41: 7.5786, 66: 2.9691, 97: 3.1325, 130: 3.3235, 256: 4.0021, 292: 3.9704, 342: 4.0506, 348: 4.0552, 356: 4.1878, 396: 4.231, 619: 4.5374, 895: 4.9415, 1838: 5.8692, 2106: 12.3318, 3892: 6.6538, 4282: 6.9174})), Row(overall=3.0, reviewText=u\"Maybe I just wasn't in the right mood for a heavily poetic book on one man's life philosophies, but this book lost me after the chapter on children. Some sections are insightful and very well written. On death, children, and love were my favorites. I'm not sure how novel these ideas were back in 1928 (?) when the book was first published, but they are nothing new today. Still, the flowery language is pretty, it's not overly long, and also it's probably one of those books that make you look cool when your reading it at a coffee shop.... so it's not all bad.This book was given to me by my dad who grew up in the 60's and 70's. It occurs to me that The Prophet seems to speak best to those from this generation (peace, love, and all that crap... you know). Maybe it's just not relevant to me? Maybe I need to approach it at a different time? Maybe I need to smoke something herbal?\", bow=[u'right', u'mood', u'poetic', u'man', u'life', u'philosophi', u'chapter', u'children', u'section', u'insight', u'death', u'children', u'love', u'favorit', u'sure', u'novel', u'idea', u'noth', u'new', u'today', u'floweri', u'languag', u'cool', u'coffe', u'shop', u'bad.thi', u'dad', u'prophet', u'best', u'generat', u'peac', u'crap', u'relev', u'differ', u'time', u'someth', u'herbal'], vector_tf=SparseVector(5000, {2: 1.0, 5: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 25: 1.0, 28: 1.0, 30: 1.0, 31: 1.0, 36: 1.0, 55: 1.0, 68: 1.0, 70: 1.0, 79: 2.0, 83: 1.0, 89: 1.0, 117: 1.0, 212: 1.0, 214: 1.0, 234: 1.0, 240: 1.0, 631: 1.0, 638: 1.0, 704: 1.0, 772: 1.0, 809: 1.0, 1030: 1.0, 1065: 1.0, 1357: 1.0, 1428: 1.0, 2006: 1.0, 2062: 1.0, 2106: 1.0}), features=SparseVector(5000, {2: 1.4132, 5: 1.8214, 11: 2.1916, 12: 2.0871, 13: 2.0846, 25: 2.4222, 28: 2.3928, 30: 2.5953, 31: 2.4682, 36: 2.8895, 55: 2.8984, 68: 2.9299, 70: 2.8728, 79: 6.4739, 83: 2.9679, 89: 3.0474, 117: 3.3311, 212: 3.6213, 214: 3.6834, 234: 3.863, 240: 3.9553, 631: 4.6717, 638: 4.7009, 704: 4.8609, 772: 5.0233, 809: 4.8377, 1030: 5.1748, 1065: 5.0805, 1357: 5.4526, 1428: 5.3887, 2006: 5.8158, 2062: 5.8363, 2106: 6.1659}))]\n",
      "root\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- bow: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- vector_tf: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "Example of first 50 words in our Vocab:\n",
      "[u'stori', u'charact', u'time', u'good', u'great', u'life', u'way', u'seri', u'mani', u'thing', u'peopl', u'novel', u'love', u'new', u'year', u'world', u'reader', u'littl', u'lot', u'page', u'end', u'famili', u'review', u'person', u'work', u'differ', u'friend', u'day', u'best', u'plot', u'man', u'someth', u'real', u'bit', u'point', u'romanc', u'chapter', u'god', u'histori', u'mysteri', u'write', u'quot', u'fact', u'word', u'old', u'place', u'star', u'relationship', u'young', u'easi']\n"
     ]
    }
   ],
   "source": [
    "review_df, vocab = indexing_pipeline(review_subset, inputCol='reviewText')\n",
    "\n",
    "# Persist this DataFrame to keep it in memory\n",
    "review_df.persist()\n",
    "\n",
    "# print the top 5 elements of the DataFrame and schema to the log\n",
    "print(review_df.take(5))\n",
    "review_df.printSchema()\n",
    "\n",
    "print(\"Example of first 50 words in our Vocab:\")\n",
    "print(vocab[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LDA Model\n",
    "\n",
    "Now that we have a DataFrame with column `features` containing a vector object representing the [Tf-Idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) values for our words, we can apply the [Latent Dirichlet allocation algorithm contained in the `ml` package](http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.clustering.LDA).\n",
    "\n",
    "For the sake of this demonstration we will be specifying 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "lda = LDA(k=5, maxIter=10, seed=42, featuresCol='features')\n",
    "model = lda.fit(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_description = model.describeTopics(20).toPandas()\n",
    "vocab = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Words Associated with Topic 0:\n",
      "[u'war' u'histori' u'god' u'american' u'peopl' u'christian' u'mani'\n",
      " u'world' u'bibl' u'time' u'polit' u'life' u'year' u'stori' u'work'\n",
      " u'novel' u'reader' u'new' u'state' u'histor']\n",
      "\n",
      "Top Words Associated with Topic 1:\n",
      "[u'stori' u'love' u'life' u'charact' u'time' u'famili' u'thing' u'way'\n",
      " u'friend' u'peopl' u'heart' u'relationship' u'seri' u'romanc' u'year'\n",
      " u'emot' u'littl' u'world' u'mani' u'good']\n",
      "\n",
      "Top Words Associated with Topic 2:\n",
      "[u'quot' u'stori' u'charact' u'novel' u'seri' u'vampir' u'life' u'man'\n",
      " u'time' u'world' u'mysteri' u'human' u'way' u'new' u'good' u'reader'\n",
      " u'great' u'famili' u'peopl' u'year']\n",
      "\n",
      "Top Words Associated with Topic 3:\n",
      "[u'seri' u'recip' u'stori' u'great' u'good' u'charact' u'time' u'lot'\n",
      " u'littl' u'way' u'page' u'thing' u'plot' u'new' u'fun' u'novel' u'food'\n",
      " u'easi' u'mani' u'love']\n",
      "\n",
      "Top Words Associated with Topic 4:\n",
      "[u'charact' u'stori' u'good' u'time' u'thing' u'novel' u'way' u'great'\n",
      " u'mani' u'chapter' u'reader' u'seri' u'lot' u'life' u'plot' u'peopl'\n",
      " u'new' u'page' u'littl' u'problem']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in model_description.iterrows():\n",
    "    desc = \"Top Words Associated with Topic {0}:\\n{1}\\n\" \\\n",
    "                .format(row['topic'], vocab[row['termIndices']])\n",
    "    print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
